# LLM Service Environment Variables

# Server
PORT=3001
NODE_ENV=development

# Google Gemini AI
GEMINI_API_KEY=your_gemini_api_key_here

# Inter-service auth (optional in dev — if unset, all requests are allowed)
# LLM_SERVICE_TOKEN=your_shared_secret_here

# Redis (optional — used for prompt response caching)
REDIS_URL=redis://localhost:6379
REDIS_CACHE_TTL=3600

# CORS (comma-separated origins)
CORS_ORIGINS=http://localhost:3000

# Rate limiting
RATE_LIMIT_MAX=60
RATE_LIMIT_WINDOW_MS=60000
